id: mlflow-model-evaluation
namespace: corn_mlops_flow

description: Extract production model from MLflow and evaluate with Evidently for data drift

inputs:
  - id: model_name
    type: STRING
    required: true
    description: "Name of the model in MLflow registry"
  - id: dataset_path
    type: STRING
    required: false
    defaults: "corn_add.csv"
    description: "Path to the new dataset for evaluation"

variables:
  mlflow_url: "https://mlflow-server-453290981886.us-central1.run.app/"
  evidently_ui_url: "https://evidently-ui-c4tqdte5jq-uc.a.run.app"
  evidently_url: "https://evidently-monitoring-c4tqdte5jq-uc.a.run.app"

tasks:
  - id: extract-production-model
    type: "io.kestra.plugin.scripts.python.Script"
    containerImage: ghcr.io/kestra-io/pydata:latest
    description: "Extract current production model from MLflow registry"
    taskRunner:
      type: io.kestra.plugin.core.runner.Process
    beforeCommands:
      - pip install mlflow==3.1.4 evidently==0.7.9 pandas scikit-learn 
    script: |
      import mlflow
      import mlflow.tracking
      from mlflow.artifacts import download_artifacts
      import json
      import os
      import joblib
      import shutil
      import pickle
      
      os.makedirs('mydir/artifacts', exist_ok=True)

      # Set MLflow tracking URI
      mlflow_tracking_uri = mlflow.set_tracking_uri("{{ vars.mlflow_url }}")
      model_name = "{{ inputs.model_name }}"
      
      # Get production model version
      client = mlflow.MlflowClient()
      
      try:
          # Get latest version in Production stage
          production_versions = client.get_latest_versions(
              model_name, 
              stages=["Production"]
          )
          
          if not production_versions:
              raise Exception(f"No model found in Production stage for {model_name}")
          
          latest_prod_version = production_versions[0]
          model_version = latest_prod_version.version          
          run_id = latest_prod_version.run_id

          print(f"MLflow URI: {mlflow_tracking_uri}")
          print(f"Run ID: {run_id}")
     
          print(f"Found production model: {model_name} version {model_version}")
          
          # Download the model
          print("Downloading model directory...")
          model_dir_path = f"runs:/{run_id}/model"
          local_model_dir = download_artifacts(model_dir_path)
              
          print(f"Downloaded model directory to: {local_model_dir}")
          print(f"Model directory contents: {os.listdir(local_model_dir)}")

          # Load MLflow model and save as simple pickle
          print("Loading and converting MLflow model...")
          model = mlflow.sklearn.load_model(model_dir_path)

          # Save the model
          model_output_path = 'mydir/artifacts/model.pkl'
          joblib.dump(model, model_output_path)
          print(f"Model saved to: {model_output_path}")

          # Copy vectorizer from downloaded model directory
          vectorizer_source = os.path.join(local_model_dir, 'vectorizer.pkl')
          vectorizer_output_path = 'mydir/artifacts/vectorizer.pkl'
          
          vectorizer_found = False
          if os.path.exists(vectorizer_source):
              shutil.copy2(vectorizer_source, vectorizer_output_path)
              vectorizer_found = True
              print(f"Vectorizer copied from {vectorizer_source} to {vectorizer_output_path}")
          else:
              print(f"Vectorizer not found at {vectorizer_source}")
              # List what's actually in the model directory
              print(f"Contents of {local_model_dir}: {os.listdir(local_model_dir)}")

          # Verify both files exist with sizes
          for artifact_name in ['model.pkl', 'vectorizer.pkl']:
              artifact_path = f'mydir/artifacts/{artifact_name}'
              if os.path.exists(artifact_path):
                  size = os.path.getsize(artifact_path)
                  print(f"{artifact_name}: {size} bytes")
              else:
                  if artifact_name == 'vectorizer.pkl':
                      print(f"Warning: {artifact_name} not found")
                  else:
                      raise FileNotFoundError(f"{artifact_name} missing after download")

          print("=== ARTIFACT DOWNLOAD COMPLETED SUCCESSFULLY ===")
          
          # Save model info for next tasks
          model_info = {
              "model_name": model_name,
              "model_version": model_version,
              "model_uri": model_dir_path,
              "model_stage": "Production",
              "vectorizer_found": vectorizer_found
          }
          
          with open("model_info.json", "w") as f:
              json.dump(model_info, f)

          # Show final directory contents
          print(f"Root directory contents: {os.listdir('.')}")
          print(f"Artifacts directory contents: {os.listdir('mydir/artifacts')}")

      except Exception as e:
          print(f"Error extracting model: {str(e)}")
          raise e
    outputFiles:
      - /**