name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.9'

jobs:
  lint-and-format:
    runs-on: ubuntu-latest
    name: Code Quality & Formatting

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install linting dependencies
      run: |
        pip install --upgrade pip
        pip install black isort flake8 mypy bandit safety

    - name: Check code formatting with Black
      run: |
        black --check --diff .

    - name: Check import sorting with isort
      run: |
        isort --check-only --diff .

    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings. Line length compatible with Black
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics

    - name: Type checking with mypy
      run: |
        mypy . --ignore-missing-imports --no-strict-optional
      continue-on-error: true  # Don't fail CI for type errors initially

    - name: Security check with bandit
      run: |
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . --severity-level medium
      continue-on-error: true

    - name: Check dependencies for security vulnerabilities
      run: |
        safety check
      continue-on-error: true

  test:
    runs-on: ubuntu-latest
    name: Run Tests
    needs: lint-and-format

    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install pytest pytest-cov pytest-xdist hyperopt

        # Install project dependencies
        if [ -f requirements.txt ]; then
            pip install -r requirements.txt
        fi
        if [ -f requirements-dev.txt ]; then
            pip install -r requirements-dev.txt
        fi
        if [ -f setup.py ]; then
            pip install -e .
        fi

    - name: Create mock data files for testing
      run: |
        # Create comprehensive mock corn.csv with all expected columns
        cat > corn.csv << 'EOF'
        Education,Gender,Age bracket,Household size,Acreage,Fertilizer amount,Laborers,Yield,Main credit source,Farm records,Main advisory source,Extension provider,Advisory format,Advisory language
        Secondary,Male,26-35,5,2.5,100,3,1500,Bank,Yes,Extension,Government,Group,English
        Primary,Female,36-45,6,3.0,120,4,1600,Cooperative,No,Radio,NGO,Individual,Local
        Tertiary,Male,46-55,4,2.0,80,2,1400,Self,Yes,TV,Private,Digital,English
        EOF

        # Create mock numpy arrays for drift monitoring
        python << 'PYTHON_EOF'
        import numpy as np
        import pickle

        # Create mock encoded training data
        X_encoded_train = np.random.rand(100, 10)
        np.save("X_encoded.npy", X_encoded_train)

        # Create mock dict vectorizer
        class MockDictVectorizer:
            def transform(self, X):
                return np.random.rand(len(X), 10)
            def get_feature_names_out(self):
                return [f"feature_{i}" for i in range(10)]
        
        with open("dict_vectorizer", "wb") as f:
            pickle.dump(MockDictVectorizer(), f)

        # Create mock model registry info
        import json
        final_run_info = {
            "run_id": "test_run_123",
            "model_name": "test_model",
            "metrics": {"rmse": 0.5, "r2": 0.8}
        }
        with open("final_run_info.json", "w") as f:
            json.dump(final_run_info, f)
        PYTHON_EOF

    - name: Setup Kaggle credentials (mock)
      run: |
        mkdir -p ~/.config/kaggle
        echo '{"username":"test","key":"test"}' > ~/.config/kaggle/kaggle.json
        chmod 600 ~/.config/kaggle/kaggle.json

    - name: Run unit tests
      run: |
        export PYTHONPATH="${PYTHONPATH}:${PWD}:${PWD}/scripts"
        pytest tests/ -v --cov=. --cov-report=xml --cov-report=html --cov-report=term
      env:
        PYTHONPATH: ${{ github.workspace }}:${{ github.workspace }}/scripts

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  build-and-test-docker:
    runs-on: ubuntu-latest
    name: Docker Build Test
    needs: [test]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Check if Dockerfile exists
      id: dockerfile-check
      run: |
        if [ -f Dockerfile ]; then
            echo "dockerfile_exists=true" >> $GITHUB_OUTPUT
        else
            echo "dockerfile_exists=false" >> $GITHUB_OUTPUT
        fi

    - name: Build Docker image
      if: steps.dockerfile-check.outputs.dockerfile_exists == 'true'
      run: |
        docker build -t corn-yield-prediction:test .

    - name: Test Docker container
      if: steps.dockerfile-check.outputs.dockerfile_exists == 'true'
      run: |
        # Basic container health check
        docker run --rm corn-yield-prediction:test python -c "import sys; print('Python version:', sys.version)"

  dependency-check:
    runs-on: ubuntu-latest
    name: Dependency Analysis

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install pip-audit
      run: pip install pip-audit

    - name: Check for outdated dependencies
      run: |
        if [ -f requirements.txt ]; then
            pip install -r requirements.txt
            pip list --outdated
        fi

    - name: Audit dependencies for vulnerabilities
      run: |
        if [ -f requirements.txt ]; then
            pip-audit -r requirements.txt
        fi
      continue-on-error: true

  notebook-tests:
    runs-on: ubuntu-latest
    name: Notebook Validation

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install notebook dependencies
      run: |
        pip install jupyter nbconvert nbformat
        if [ -f requirements.txt ]; then
            pip install -r requirements.txt
        fi

    - name: Execute notebooks
      run: |
        # Find and execute all notebooks
        find . -name "*.ipynb" -not -path "./.git/*" -not -path "./.*" | while read notebook; do
            echo "Testing notebook: $notebook"
            jupyter nbconvert --to notebook --execute --inplace "$notebook" || echo "‚ùå Failed: $notebook"
        done
      continue-on-error: true

  pre-commit-hooks:
    runs-on: ubuntu-latest
    name: Pre-commit Hooks

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install pre-commit
      run: pip install pre-commit

    - name: Run pre-commit on all files
      run: |
        if [ -f .pre-commit-config.yaml ]; then
            pre-commit run --all-files
        else
            echo "No .pre-commit-config.yaml found, skipping pre-commit checks"
        fi
      continue-on-error: true